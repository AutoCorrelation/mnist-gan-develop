{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f032eb2e",
   "metadata": {},
   "source": [
    "- 출처 : https://tutorials.pytorch.kr/beginner/dcgan_faces_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ef4f21",
   "metadata": {},
   "source": [
    "#### 1. 초기설정 : 모델 import 및 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2795d41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "# 코드 실행결과의 동일성을 위해 무작위 시드를 설정합니다\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # 만일 새로운 결과를 원한다면 주석을 없애면 됩니다\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "# torch.use_deterministic_algorithms(True) # 결과 재현을 위해 필요합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cff585e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋의 경로\n",
    "dataroot = \"data/MNIST\"\n",
    "\n",
    "# dataloader에서 사용할 쓰레드 수\n",
    "workers = 4\n",
    "\n",
    "# 배치 크기\n",
    "batch_size = 128\n",
    "\n",
    "# 이미지의 크기입니다. 모든 이미지를 변환하여 64로 크기가 통일됩니다.\n",
    "image_size = 28\n",
    "\n",
    "# 이미지의 채널 수로, RGB 이미지이기 때문에 3으로 설정합니다.\n",
    "nc = 1\n",
    "\n",
    "# 잠재공간 벡터의 크기 (예. 생성자의 입력값 크기)\n",
    "nz = 100\n",
    "\n",
    "# 학습할 에폭 수\n",
    "num_epochs = 11\n",
    "\n",
    "# 옵티마이저의 학습률\n",
    "G_lr = 0.0004\n",
    "D_lr = 0.0001\n",
    "\n",
    "# Adam 옵티마이저의 beta1 하이퍼파라미터\n",
    "beta1 = 0.5\n",
    "\n",
    "# 사용가능한 gpu 번호. CPU를 사용해야 하는경우 0으로 설정하세요\n",
    "ngpu = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19aaa640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader를 정의해봅시다\n",
    "batch_size = 128\n",
    "image_size = 28\n",
    "channels = 1\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "# GPU 사용여부를 결정해 줍니다\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "\n",
    "# 학습 데이터들 중 몇가지 이미지들을 화면에 띄워봅시다\n",
    "real_batch = next(iter(train_loader))\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Training Images\")\n",
    "plt.imshow(np.transpose(torchvision.utils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e5dd6a0",
   "metadata": {},
   "source": [
    "#### 2. 모델 관련된 정의 (가중치초기화, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e72689",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "def weights_init_he(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight.data, nonlinearity='relu')\n",
    "    elif classname.find('Conv') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight.data, mode='fan_out', nonlinearity='relu')\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.constant_(m.weight.data, 1)\n",
    "        nn.init.constant_(m.bias.data, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8353a095",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.BatchNorm1d(256, momentum=0.2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Linear(256, 512),\n",
    "            nn.BatchNorm1d(512, momentum=0.2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Linear(512, 1024),\n",
    "            nn.BatchNorm1d(1024, momentum=0.2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            \n",
    "            nn.Linear(1024, image_size * image_size * channels),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "        self.latent_dim = latent_dim\n",
    "    def forward(self, z):\n",
    "        out = self.model(z)\n",
    "        out = out.view(z.size(0), channels, image_size, image_size)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b8ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자를 만듭니다\n",
    "netG = Generator(nz).to(device)\n",
    "\n",
    "netG.apply(weights_init_he)\n",
    "\n",
    "# 모델의 구조를 출력합니다\n",
    "print(netG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242f1b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(image_size * image_size * channels, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86bb219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 생성자를 만듭니다\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "netD.apply(weights_init_he)\n",
    "\n",
    "# 모델의 구조를 출력합니다\n",
    "print(netD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e45a19",
   "metadata": {},
   "source": [
    "#### 2.5 옵티마이저 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a251feef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ``BCELoss`` 함수의 인스턴스를 초기화합니다\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# 생성자의 학습상태를 확인할 잠재 공간 벡터를 생성합니다\n",
    "fixed_noise = torch.randn(16, nz, device=device)\n",
    "\n",
    "# 학습에 사용되는 참/거짓의 라벨을 정합니다\n",
    "real_label = 1.\n",
    "fake_label = 0.\n",
    "\n",
    "# G와 D에서 사용할 Adam옵티마이저를 생성합니다\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=D_lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=G_lr, betas=(beta1, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec65e4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from adabelief_pytorch import AdaBelief\n",
    "optimizerG = AdaBelief(netG.parameters(), lr=1e-4, eps=1e-16, betas=(0.9,0.999), weight_decouple = True, rectify = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ec5901",
   "metadata": {},
   "source": [
    "#### 3. 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e92593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 과정\n",
    "\n",
    "# 학습상태를 체크하기 위해 손실값들을 저장합니다\n",
    "img_list = []\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "G_losses_perEpoch = []\n",
    "D_losses_perEpoch = []\n",
    "iters = 0\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "# 에폭(epoch) 반복\n",
    "for epoch in range(num_epochs):\n",
    "    # 한 에폭 내에서 배치 반복\n",
    "    g_losses_epoch = 0.0\n",
    "    d_losses_epoch = 0.0\n",
    "    for i, (data, _) in enumerate(train_loader):\n",
    "\n",
    "        ############################\n",
    "        # (1) D 신경망을 업데이트 합니다: log(D(x)) + log(1 - D(G(z)))를 최대화 합니다\n",
    "        ###########################\n",
    "        ## 진짜 데이터들로 학습을 합니다\n",
    "        netD.zero_grad()\n",
    "        # 배치들의 사이즈나 사용할 디바이스에 맞게 조정합니다\n",
    "        real_cpu = data.to(device,non_blocking=True)\n",
    "        b_size = real_cpu.size(0)\n",
    "        label = torch.full((b_size,), real_label,\n",
    "                           dtype=torch.float, device=device)\n",
    "        # 진짜 데이터들로 이루어진 배치를 D에 통과시킵니다\n",
    "        output = netD(real_cpu).view(-1)\n",
    "        # 손실값을 구합니다\n",
    "        errD_real = criterion(output, label)\n",
    "        # 역전파의 과정에서 변화도를 계산합니다\n",
    "        errD_real.backward()\n",
    "        D_x = output.mean().item()\n",
    "\n",
    "        ## 가짜 데이터들로 학습을 합니다\n",
    "        # 생성자에 사용할 잠재공간 벡터를 생성합니다\n",
    "        noise = torch.randn(b_size, nz, device=device)\n",
    "        # G를 이용해 가짜 이미지를 생성합니다\n",
    "        fake = netG(noise)\n",
    "        label.fill_(fake_label)\n",
    "        # D를 이용해 데이터의 진위를 판별합니다\n",
    "        output = netD(fake.detach()).view(-1)\n",
    "        # D의 손실값을 계산합니다\n",
    "        errD_fake = criterion(output, label)\n",
    "        # 역전파를 통해 변화도를 계산합니다. 이때 앞서 구한 변화도에 더합니다(accumulate)\n",
    "        errD_fake.backward()\n",
    "        D_G_z1 = output.mean().item()\n",
    "        # 가짜 이미지와 진짜 이미지 모두에서 구한 손실값들을 더합니다\n",
    "        # 이때 errD는 역전파에서 사용되지 않고, 이후 학습 상태를 리포팅(reporting)할 때 사용합니다\n",
    "        errD = errD_real + errD_fake\n",
    "        # D를 업데이트 합니다\n",
    "        optimizerD.step()\n",
    "\n",
    "        ############################\n",
    "        # (2) G 신경망을 업데이트 합니다: log(D(G(z)))를 최대화 합니다\n",
    "        ###########################\n",
    "        netG.zero_grad()\n",
    "        label.fill_(real_label)  # 생성자의 손실값을 구하기 위해 진짜 라벨을 이용할 겁니다\n",
    "        # 우리는 방금 D를 업데이트했기 때문에, D에 다시 가짜 데이터를 통과시킵니다.\n",
    "        # 이때 G는 업데이트되지 않았지만, D가 업데이트 되었기 때문에 앞선 손실값가 다른 값이 나오게 됩니다\n",
    "        output = netD(fake).view(-1)\n",
    "        # G의 손실값을 구합니다\n",
    "        errG = criterion(output, label)\n",
    "        # G의 변화도를 계산합니다\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item()\n",
    "        # G를 업데이트 합니다\n",
    "        optimizerG.step()\n",
    "\n",
    "        # 훈련 상태를 출력합니다\n",
    "        # D_G_z1 -> 생성자 업데이트 후 D_G_z2\n",
    "        if i % 50 == 0:\n",
    "            print('[%d/%d][%03d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
    "                  % (epoch, num_epochs, i, len(train_loader),\n",
    "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
    "\n",
    "        # 이후 그래프를 그리기 위해 손실값들을 저장해둡니다\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "\n",
    "        # fixed_noise를 통과시킨 G의 출력값을 저장해둡니다\n",
    "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(train_loader)-1)):\n",
    "            with torch.no_grad():\n",
    "                fake = netG(fixed_noise).detach().cpu()\n",
    "            img_list.append(torchvision.utils.make_grid(fake, padding=2, normalize=True))\n",
    "\n",
    "        iters += 1\n",
    "        g_losses_epoch += errG.item()\n",
    "        d_losses_epoch += errD.item()\n",
    "\n",
    "    D_losses_perEpoch.append(d_losses_epoch / len(train_loader))\n",
    "    G_losses_perEpoch.append(g_losses_epoch / len(train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b173f0",
   "metadata": {},
   "source": [
    "BCE 기반 GAN 기준에서:\n",
    "\n",
    "errD 이론 기준: 1.386\n",
    "\n",
    "errG 이론 기준: 0.693"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c65c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.title(\"Generator and Discriminator Loss During Training\")\n",
    "plt.plot(G_losses,label=\"G\")\n",
    "plt.plot(D_losses,label=\"D\")\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1fc781",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(D_losses[-1])\n",
    "print(G_losses[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce7b4720",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.axis(\"off\")\n",
    "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
    "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
    "\n",
    "HTML(ani.to_jshtml())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b1d358",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader에서 진짜 데이터들을 가져옵니다\n",
    "real_batch = next(iter(train_loader))\n",
    "\n",
    "# 진짜 이미지들을 화면에 출력합니다\n",
    "plt.figure(figsize=(15,15))\n",
    "plt.subplot(1,2,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "plt.imshow(np.transpose(torchvision.utils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
    "\n",
    "# 가짜 이미지들을 화면에 출력합니다\n",
    "plt.subplot(1,2,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6fcfced",
   "metadata": {},
   "source": [
    "| 항목       | 정상 범위      | 내 값        |\n",
    "| -------- | ---------- | ---------- | \n",
    "| mean     | -0.2 ~ 0.2 | **-0.716** | \n",
    "| mean std | 0.2 ~ 0.5  | **0.084**  | \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db311bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the output distribution of the Generator\n",
    "with torch.no_grad():\n",
    "    noise = torch.randn(1000, nz, device=device)  # Generate a large batch of noise\n",
    "    generated_images = netG(noise).view(1000, -1)  # Flatten the images\n",
    "    output_means = generated_images.mean(dim=1).cpu().numpy()  # Compute mean per image\n",
    "    output_overall_mean = output_means.mean()  # Overall mean\n",
    "    output_overall_std = output_means.std()  # Overall standard deviation\n",
    "    print(f\"Generator Output Mean (per image): {output_overall_mean:.4f}\")\n",
    "    print(f\"Generator Output Std Dev (per image): {output_overall_std:.4f}\")\n",
    "    plt.hist(output_means, bins=30, alpha=0.7, color='blue', edgecolor='black')\n",
    "    plt.title(\"Histogram of Generator Output Means\")\n",
    "    plt.xlabel(\"Mean Pixel Value\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
